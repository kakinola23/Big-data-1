{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"History\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|         value|\n",
      "+--------------+\n",
      "|P,P,A,A,A,P,NB|\n",
      "|N,N,A,A,A,N,NB|\n",
      "|A,A,A,A,A,A,NB|\n",
      "|P,P,P,P,P,P,NB|\n",
      "|N,N,P,P,P,N,NB|\n",
      "|A,A,P,P,P,A,NB|\n",
      "|P,P,A,P,P,P,NB|\n",
      "|P,P,P,A,A,P,NB|\n",
      "|P,P,A,P,A,P,NB|\n",
      "|P,P,A,A,P,P,NB|\n",
      "|P,P,P,P,A,P,NB|\n",
      "|P,P,P,A,P,P,NB|\n",
      "|N,N,A,P,P,N,NB|\n",
      "|N,N,P,A,A,N,NB|\n",
      "|N,N,A,P,A,N,NB|\n",
      "|N,N,A,P,A,N,NB|\n",
      "|N,N,A,A,P,N,NB|\n",
      "|N,N,P,P,A,N,NB|\n",
      "|N,N,P,A,P,N,NB|\n",
      "|A,A,A,P,P,A,NB|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"text\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"Qualitative_Bankruptcy.txt\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_Double_Value = { 'P' : 3.0, 'A' : 2.0, 'N' : 1.0, 'NB': 1.0, 'B': 0.0 }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P,P,A,A,A,P,NB'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[88] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def line_parser(line):\n",
    "    tokens_df = line.split(',')\n",
    "    label_df = get_Double_Value[tokens_df[-1]]\n",
    "    features_df = list(map(lambda t: get_Double_Value[t], tokens_df[:-1]))\n",
    "    return LabeledPoint(label_df, features_df)\n",
    "\n",
    "parsed_d= df.rdd.map(lambda x: line_parser(x[0]))\n",
    "parsed_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0,[3.0,3.0,2.0,2.0,2.0,3.0])\n"
     ]
    }
   ],
   "source": [
    "print(parsed_d.take(1)[0])\n",
    "train_d, test_d = parsed_d.randomSplit([0.6, 0.4], seed = 0)\n",
    "\n",
    "model_fit = LogisticRegressionWithLBFGS.train(train_d, numClasses = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = test_d.map(lambda point: (point.label,  model_fit.predict(point.features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error Rate = 0.2037037037037037\n"
     ]
    }
   ],
   "source": [
    "train_error = len(list(filter(lambda r: (r[0] != r[1]), label_pred.collect())))/test_d.count()\n",
    "print(f\"Training Error Rate = {train_error}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
